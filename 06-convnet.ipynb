{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Convolution Networks\n",
    " \n",
    " * Outline\n",
    "  - Today we will show how to train a ConvNet using PyTorch\n",
    "  - We will also illustrate how the ConvNet makes use of specific assumptions\n",
    "\n",
    "More info about *kernels* in convolution networks: https://towardsdatascience.com/types-of-convolution-kernels-simplified-f040cb307c37 (see first sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Natural data properties:\n",
    "  - *Stationarity*: Patterns repeat across dimensionality. ⇒ parameters sharing\n",
    "  - *Locallity*: Nearby points are more correlated than points far away.⇒ sparsity\n",
    "  - *Compositionality*: Everything in nature is composed of parts that are composed of sub-parts and so on.\n",
    " \n",
    "\n",
    " * To perform well, we need to incorporate some prior knowledge about the problem\n",
    "  - Assumptions helps us when they are true\n",
    "  - They hurt us when they are not\n",
    "  - We want to make just the right amount of assumptions, not more than that\n",
    "\n",
    "\n",
    " * In Deep Learning\n",
    "  - Many layers: compositionality\n",
    "  - Convolutions: locality + stationarity of images\n",
    "  - Pooling: Invariance of object class to translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from res.plot_lib import plot_data, plot_model, set_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# function to count number of parameters\n",
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device : {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset (MNIST)\n",
    "\n",
    "\n",
    "We can use some PyTorch DataLoader utilities for this. This will download, shuffle, normalize data and arrange it in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size  = 28*28   # images are 28x28 pixels\n",
    "output_size = 10      # there are 10 classes\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show some images\n",
    "plt.figure(figsize=(16, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    plt.imshow(image.squeeze().numpy())\n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous explanations:\n",
    "\n",
    " - tensor view: https://pytorch.org/docs/stable/tensor_view.html - It generates a `view` of the original tensor with other shape but same data (reshaping)\n",
    " \n",
    " ```\n",
    "  t = torch.rand([[a b c][d e f][g h i][j k l]])  # 4x3\n",
    "  b = t.view(2, 6)\n",
    "  b\n",
    "   >> out: [[a b c d e f],[g h i j k l]]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connect 2 layers Network\n",
    "class FC2Layer(nn.Module):\n",
    "    def __init__(self, input_size, n_hidden, output_size):\n",
    "        super(FC2Layer, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, n_hidden), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(n_hidden, n_hidden), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(n_hidden, output_size), \n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        return self.network(x)\n",
    "    \n",
    "# Convolutional Neural Network\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, n_feature, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.n_feature = n_feature\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(n_feature*4*4, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = x.view(-1, self.n_feature*4*4)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on a GPU: device string\n",
    "\n",
    "Switching between CPU and GPU in PyTorch is controlled via a device string, which will seemlessly determine whether GPU is available, falling back to CPU if not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "\n",
    "def train(epoch, model, perm=torch.arange(0, 784).long()):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # permute pixels\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, perm=torch.arange(0, 784).long()):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # permute pixels\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss                                                               \n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a small fully-connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 8 # number of hidden units\n",
    "\n",
    "model_fnn = FC2Layer(input_size, n_hidden, output_size)\n",
    "model_fnn.to(device)\n",
    "optimizer = optim.SGD(model_fnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_fnn)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_fnn)\n",
    "    test(model_fnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a ConvNet with the same number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings \n",
    "n_features = 6 # number of feature maps\n",
    "\n",
    "model_cnn = CNN(input_size, n_features, output_size)\n",
    "model_cnn.to(device)\n",
    "optimizer = optim.SGD(model_cnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_cnn)\n",
    "    test(model_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ConvNet performs better with the same number of parameters, thanks to its use of prior knowledge about images\n",
    "\n",
    "* Use of convolution: Locality and stationarity in images\n",
    "* Pooling: builds in some translation invariance\n",
    "\n",
    "# What happens if the assumptions are no longer true?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = torch.randperm(784)\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i in range(10):\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    # permute pixels\n",
    "    image_perm = image.view(-1, 28*28).clone()\n",
    "    image_perm = image_perm[:, perm]\n",
    "    image_perm = image_perm.view(-1, 1, 28, 28)\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(image.squeeze().numpy())\n",
    "    plt.axis('off')\n",
    "    plt.subplot(4, 5, i + 11)\n",
    "    plt.imshow(image_perm.squeeze().numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet with permuted pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings \n",
    "n_features = 6 # number of feature maps\n",
    "\n",
    "model_cnn = CNN(input_size, n_features, output_size)\n",
    "model_cnn.to(device)\n",
    "optimizer = optim.SGD(model_cnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_cnn, perm)\n",
    "    test(model_cnn, perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully-Connected with Permuted Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 8    # number of hidden units\n",
    "\n",
    "model_fnn = FC2Layer(input_size, n_hidden, output_size)\n",
    "model_fnn.to(device)\n",
    "optimizer = optim.SGD(model_fnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_fnn)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_fnn, perm)\n",
    "    test(model_fnn, perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ConvNet's performance drops when we permute the pixels, but the Fully-Connected Network's performance stays the same\n",
    "\n",
    "* ConvNet makes the assumption that pixels lie on a grid and are stationary/local\n",
    "* It loses performance when this assumption is wrong\n",
    "* The fully-connected network does not make this assumption\n",
    "* It does less well when it is true, since it doesn't take advantage of this prior knowledge\n",
    "* But it doesn't suffer when the assumption is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(('NN image', 'CNN image',\n",
    "         'CNN scrambled', 'NN scrambled'),\n",
    "        accuracy_list, width=0.4)\n",
    "plt.ylim((min(accuracy_list)-5, 96))\n",
    "plt.ylabel('Accuracy [%]')\n",
    "for tick in plt.gca().xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(20)\n",
    "plt.title('Performance comparison');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(model_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(model_fnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pDL] *",
   "language": "python",
   "name": "conda-env-.conda-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
